# -*- coding: UTF-8 -*-.
import argparse
from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score
from sklearn.metrics import confusion_matrix
from sklearn.svm import SVC
from sklearn.svm import LinearSVC
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.preprocessing import MinMaxScaler
from sklearn.grid_search import GridSearchCV
import tflearn
import matplotlib.pyplot as plt
import numpy as np
import sys
sys.path.append("./lib")
from common import read_file, cross_validation, hot_enconding, concatenate_features, prob_to_class, prob_to_class_threshold

N_GOODWARES = 100
N_MALWARES = 1000
N_FEATURES = 100
GW_TEST_SIZE = 0.1
MW_TEST_SIZE = 0.1
THRESHOLD = True

def params():
    parser = argparse.ArgumentParser()
    parser.add_argument('goodwares_csv', help='Goodwares CSV location')
    parser.add_argument('malwares_csv', help='Malwares CSV Location')
    params = parser.parse_args()
    return params.goodwares_csv, params.malwares_csv

# get params
gw_csv, mw_csv = params()

# read goodwares and malwares
gw_features, gw_identifiers, gw_dlls, gw_symbols = read_file(gw_csv)
mw_features, mw_identifiers, mw_dlls, mw_symbols, years = read_ymd_csvs(mw_csv)

print "Goodwares:",len(gw_features)
print "Malwares:", len(mw_features)

# create label arrays
gw_label = np.zeros(len(gw_features))
mw_label = np.ones(len(mw_features))

# cross validation

# goodwares cross validation
gw_features_train, gw_features_test, gw_identifiers_train, gw_identifiers_test, gw_dlls_train, gw_dlls_test, gw_symbols_train, gw_symbols_test, gw_labels_train, gw_labels_test = cross_validation(gw_features, gw_identifiers, gw_dlls, gw_symbols, gw_label,test_size=GW_TEST_SIZE)

# malwares cross validation
mw_features_train, mw_features_test, mw_identifiers_train, mw_identifiers_test, mw_dlls_train, mw_dlls_test, mw_symbols_train, mw_symbols_test, mw_labels_train, mw_labels_test = cross_validation(mw_features, mw_identifiers, mw_dlls, mw_symbols, mw_label,test_size=MW_TEST_SIZE)

# create train and test sets - concatenate goodwares and malwares
features_train = np.concatenate((gw_features_train, mw_features_train),axis=0)
features_test = np.concatenate((gw_features_test, mw_features_test),axis=0)
identifiers_train = np.concatenate((gw_identifiers_train, mw_identifiers_train),axis=0)
identifiers_test = np.concatenate((gw_identifiers_test, mw_identifiers_test),axis=0)
dlls_train = np.concatenate((gw_dlls_train, mw_dlls_train),axis=0)
dlls_test = np.concatenate((gw_dlls_test, mw_dlls_test),axis=0)
symbols_train = np.concatenate((gw_symbols_train, mw_symbols_train),axis=0)
symbols_test = np.concatenate((gw_symbols_test, mw_symbols_test),axis=0)
labels_train = np.concatenate((gw_labels_train, mw_labels_train),axis=0)
labels_test = np.concatenate((gw_labels_test, mw_labels_test),axis=0)

# print number of train and test examples
print "Train:",features_train.shape[0]
print "Test:",features_test.shape[0]

# train tfidf for each textual feature
identifiers_tfidf = TfidfVectorizer(max_features=N_FEATURES)
identifiers_tfidf.fit(identifiers_train)
identifiers_train = identifiers_tfidf.transform(identifiers_train)
identifiers_test = identifiers_tfidf.transform(identifiers_test)
dlls_tfidf = TfidfVectorizer(max_features=N_FEATURES)
dlls_tfidf.fit(dlls_train)
dlls_train = dlls_tfidf.transform(dlls_train)
dlls_test = dlls_tfidf.transform(dlls_test)
symbols_tfidf = TfidfVectorizer(max_features=N_FEATURES)
symbols_tfidf.fit(symbols_train)
symbols_train = symbols_tfidf.transform(symbols_train)
symbols_test = symbols_tfidf.transform(symbols_test)

# concatenate numerical and textual features
X_train = concatenate_features(features_train,[identifiers_train, dlls_train, symbols_train])
X_test = concatenate_features(features_test,[identifiers_test, dlls_test, symbols_test])

# normalize features
normalization = MinMaxScaler()
normalization.fit(X_train)
X_train = normalization.transform(X_train)
X_test = normalization.transform(X_test)


# use in a classifier
clfs_n = ["mlp", "svc", "knn", "decision tree", "randomforest"]
clfs = []
# Building deep neural network
net = tflearn.input_data(shape=[None, X_train.shape[1]])
net = tflearn.fully_connected(net, X_train.shape[1]/2, activation='relu')
net = tflearn.fully_connected(net, X_train.shape[1]/3, activation='relu')
net = tflearn.fully_connected(net, 2, activation='softmax')
net = tflearn.regression(net)
# Training
clfs.append(tflearn.DNN(net, tensorboard_verbose=0))
clfs.append(SVC(kernel='linear', probability=True))
# clfs.append(LinearSVC())
clfs.append(KNeighborsClassifier(5))
clfs.append(DecisionTreeClassifier())
clfs.append(RandomForestClassifier())
hot_labels_train = hot_enconding(labels_train)


# fprs = []
# fnrs = []
# accs = []
# f1s = []
# thresholds = []
if THRESHOLD:
    for n in range(len(clfs_n)):
        if clfs_n[n] == 'mlp':
            clfs[n].fit(X_train, hot_labels_train)
        else:
            clfs[n].fit(X_train, labels_train)
        csv_out = open(clfs_n[n] + "_results.csv", "a")
        c = csv.writer(csv_out)
        c.writerow(["threshold", "accuracy", "f1score", "fpr", "fnr", "tpr", "tnr"])
        if clfs_n[n] == 'mlp':
            pred = clfs[n].predict(X_test)
        else:
            pred = clfs[n].predict_proba(X_test)
        for t in np.arange(0,1,0.0005):
            pred_t = prob_to_class_threshold(pred, t)
            print "Threshold:",t
            # print "FAR:", far(labels_test, pred)
            # print "FRR:", frr(labels_test, pred)
            # acc = accuracy(labels_test, pred)
            # print "Accuracy:", acc
            print "Accuracy:", accuracy_score(labels_test, pred_t)
            print "F1Score:", f1_score(labels_test, pred_t)
            print "Recall:", recall_score(labels_test, pred_t)
            print "Precision:", precision_score(labels_test, pred_t)
            acc = accuracy_score(labels_test, pred_t)
            cm = confusion_matrix(labels_test, pred_t)
            # Thus in binary classification, the count of true negatives is C_{0,0}, false negatives is C_{1,0}, true positives is C_{1,1} and false positives is C_{0,1}.
            print cm
            tn = cm[0][0]
            fn = cm[1][0]
            tp = cm[1][1]
            fp = cm[0][1]
            f1 = f1_score(labels_test, pred_t)
            tpr = tp/float(tp+fn)
            fnr = 1 - tpr
            fpr = fp/float(fn+tn)
            tnr = tn/float(fp+tn)
            print "FPR:",fpr
            print "FNR:",fnr
            c.writerow([t, acc, f1, fpr, fnr, tpr, tnr])

else:
    pred = clf.predict(X_test)
    # if classifier == 'mlp':
        # pred = prob_to_class(pred)
    print "Accuracy:", accuracy_score(labels_test, pred)
    print "F1Score:", f1_score(labels_test, pred)
    print confusion_matrix(labels_test, pred)
