# -*- coding: UTF-8 -*-.
import argparse
import os
import csv
import numpy as np
from sklearn.metrics import accuracy_score, f1_score
from sklearn.metrics import confusion_matrix
from sklearn.svm import SVC
from sklearn.svm import LinearSVC
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.preprocessing import MinMaxScaler
import tflearn
import re
import math
import random
import matplotlib.pyplot as plt


N_GOODWARES = 100
N_MALWARES = 1000
N_FEATURES = 100
GW_TEST_SIZE = 0.1
MW_TEST_SIZE = 0.1
THRESHOLD = True
FEATURES = [ "BaseOfCode", "BaseOfData", "Characteristics",
             "DllCharacteristics", "Entropy", "FileAlignment", "FileType", "FormatedTimeDateSteamp", "Fuzzy", "Identify", "ImageBase", "ImportedDlls", "ImportedSymbols", "MD5", "Machine", "Magic", "Name", "NumberOfRvaAndSizes", "NumberOfSections", "NumberOfSymbols", "PE_TYPE", "PointerToSymbolTable", "SHA1", "Size", "SizeOfCode", "SizeOfHeaders", "SizeOfImage", "SizeOfInitializedData", "SizeOfOptionalHeader", "SizeOfUninitializedData", "TimeDateStamp"]

USED_FEATURES = [ "BaseOfCode", "BaseOfData", "Characteristics",
                  "DllCharacteristics", "FileAlignment", "ImageBase", "Machine", "Magic", "NumberOfRvaAndSizes", "NumberOfSections", "NumberOfSymbols", "PE_TYPE", "PointerToSymbolTable", "Size", "SizeOfCode", "SizeOfHeaders", "SizeOfImage", "SizeOfInitializedData", "SizeOfOptionalHeader", "SizeOfUninitializedData", "TimeDateStamp"]

def params():
    parser = argparse.ArgumentParser()
    parser.add_argument('goodwares_csv', help='Goodwares CSV location')
    parser.add_argument('malwares_csv', help='Malwares CSV Location')
    params = parser.parse_args()
    return params.goodwares_csv, params.malwares_csv

def clear_text(text):
    text = text.replace("'","").replace("[","").replace("]","")
    text = re.sub("[^A-Za-z0-9]+","", text)
    return text.lower()

def read_file(input_file):
    with open(input_file, 'rb') as file:
        reader = csv.DictReader(file)
        features = []
        identifiers = []
        imported_dlls = []
        imported_symbols = []
        for row in reader:
            example = []
            for f in USED_FEATURES:
                example.append(int(row[f]))
            example.append(float(row["Entropy"]))
            # get compiler and packer info
            id_regex = r"\[\'[^']*\'\]"
            ident = re.findall(id_regex,row["Identify"])
            identify = ""
            for i in ident:
                identify += clear_text(i) + " "
            # get imported dlls
            dll_regex = r"\'[^']*\'"
            i_dlls = re.findall(dll_regex,row["ImportedDlls"])
            dlls = ""
            for d in i_dlls:
                dlls += clear_text(d) + " "
            # get imported symbols
            i_symbols = re.findall(dll_regex,row["ImportedSymbols"])
            symbols = ""
            for d in i_symbols:
                symbols += clear_text(d) + " "
            # apped texts to their arrays
            identifiers.append(identify)
            imported_dlls.append(dlls)
            imported_symbols.append(symbols)
            # append current example features
            features.append(example)
    features = np.array(features)
    identifiers = np.array(identifiers)
    imported_dlls = np.array(imported_dlls)
    imported_symbols = np.array(imported_symbols)
    return features, identifiers, imported_dlls, imported_symbols

def cross_validation(features, identifiers, dlls, symbols, labels, test_size):
    # total data
    n_data = len(features)
    # number of test data
    n_test = math.ceil(n_data*test_size)
    # get random n_test indexes
    indexes = random.sample(range(n_data), int(n_test))
    features_test = []
    features_train = []
    identifiers_test = []
    identifiers_train = []
    dlls_test = []
    dlls_train = []
    symbols_test = []
    symbols_train = []
    labels_test = []
    labels_train = []
    for i in range(len(features)):
        if i not in indexes:
            # add data i to train
            features_train.append(features[i])
            identifiers_train.append(identifiers[i])
            dlls_train.append(dlls[i])
            symbols_train.append(symbols[i])
            labels_train.append(labels[i])
        else:
            # add data i to test
            features_test.append(features[i])
            identifiers_test.append(identifiers[i])
            dlls_test.append(dlls[i])
            symbols_test.append(symbols[i])
            labels_test.append(labels[i])
    return features_train, features_test, identifiers_train, identifiers_test, dlls_train, dlls_test, symbols_train, symbols_test, labels_train, labels_test

def concatenate_features(features, array):
    X = []
    for i in range(features.shape[0]):
        x = features[i]
        for j in array:
            x = np.concatenate((x,j[i].toarray()[0]))
        X.append(x)
    return np.array(X)


def hot_encondig(y):
    new_y = []
    for i in y:
        temp = np.zeros(2)
        temp[int(i)] = 1
        new_y.append(temp)
    return np.array(new_y)

def prob_to_class(pred):
    new_pred = []
    for i in pred:
        temp = np.array(i).argsort()[::-1][0]
        new_pred.append(temp)
    return new_pred

def prob_to_class_threshold(pred, threshold):
    new_pred = []
    for i in pred:
        dist = i[np.array(i).argsort()[::-1][0]]
        if dist > threshold:
            temp = np.array(i).argsort()[::-1][0]
        else:
            temp = 0
        new_pred.append(temp)
    return new_pred

def accuracy(labels, pred):
    # (number of items classifieds correctly)/(total)
    pred = np.array(pred)
    labels = np.array(labels)
    where = np.where(pred != "RJ")[0]
    ac_labels = labels[where].astype(int)
    ac_pred = pred[where].astype(int)
    right = np.sum(ac_labels==ac_pred)
    total = len(where)
    div = right/float(total)
    return float(div)

# return false acceptance rate (FAR)
# percentage of invalid inputs which are incorrectly accepted
def far(labels, pred):
    pred = np.array(pred)
    labels = np.array(labels)
    where = np.where(pred != "RJ")[0]
    ac_labels = labels[where].astype(int)
    ac_pred = pred[where].astype(int)
    if len(where) == 0:
        return 1
    else:
        return np.sum(ac_labels!=ac_pred)/float(len(where))

# return false rejection rate (FRR)
# percentage of valid inputs which are incorrectly rejected
def frr(labels, pred):
    pred = np.array(pred)
    labels = np.array(labels)
    where = np.where(pred == "RJ")[0]
    if len(where) == 0:
        return 0
    else:
        ac_pred = pred[where]
        return ac_pred.size/float(len(where))


# get params
gw_csv, mw_csv = params()

# read goodwares and malwares
gw_features, gw_identifiers, gw_dlls, gw_symbols = read_file(gw_csv)
mw_features, mw_identifiers, mw_dlls, mw_symbols = read_file(mw_csv)

print "Goodwares:",len(gw_features)
print "Malwares:", len(mw_features)

# create label arrays
gw_label = np.zeros(len(gw_features))
mw_label = np.ones(len(mw_features))

# cross validation

# goodwares cross validation
gw_features_train, gw_features_test, gw_identifiers_train, gw_identifiers_test, gw_dlls_train, gw_dlls_test, gw_symbols_train, gw_symbols_test, gw_labels_train, gw_labels_test = cross_validation(gw_features, gw_identifiers, gw_dlls, gw_symbols, gw_label,test_size=GW_TEST_SIZE)

# malwares cross validation
mw_features_train, mw_features_test, mw_identifiers_train, mw_identifiers_test, mw_dlls_train, mw_dlls_test, mw_symbols_train, mw_symbols_test, mw_labels_train, mw_labels_test = cross_validation(mw_features, mw_identifiers, mw_dlls, mw_symbols, mw_label,test_size=MW_TEST_SIZE)

# create train and test sets - concatenate goodwares and malwares
features_train = np.concatenate((gw_features_train, mw_features_train),axis=0)
features_test = np.concatenate((gw_features_test, mw_features_test),axis=0)
identifiers_train = np.concatenate((gw_identifiers_train, mw_identifiers_train),axis=0)
identifiers_test = np.concatenate((gw_identifiers_test, mw_identifiers_test),axis=0)
dlls_train = np.concatenate((gw_dlls_train, mw_dlls_train),axis=0)
dlls_test = np.concatenate((gw_dlls_test, mw_dlls_test),axis=0)
symbols_train = np.concatenate((gw_symbols_train, mw_symbols_train),axis=0)
symbols_test = np.concatenate((gw_symbols_test, mw_symbols_test),axis=0)
labels_train = np.concatenate((gw_labels_train, mw_labels_train),axis=0)
labels_test = np.concatenate((gw_labels_test, mw_labels_test),axis=0)

# print number of train and test examples
print "Train:",features_train.shape[0]
print "Test:",features_test.shape[0]

# train tfidf for each textual feature
identifiers_tfidf = TfidfVectorizer(max_features=N_FEATURES)
identifiers_tfidf.fit(identifiers_train)
identifiers_train = identifiers_tfidf.transform(identifiers_train)
identifiers_test = identifiers_tfidf.transform(identifiers_test)
dlls_tfidf = TfidfVectorizer(max_features=N_FEATURES)
dlls_tfidf.fit(dlls_train)
dlls_train = dlls_tfidf.transform(dlls_train)
dlls_test = dlls_tfidf.transform(dlls_test)
symbols_tfidf = TfidfVectorizer(max_features=N_FEATURES)
symbols_tfidf.fit(symbols_train)
symbols_train = symbols_tfidf.transform(symbols_train)
symbols_test = symbols_tfidf.transform(symbols_test)

# concatenate numerical and textual features
X_train = concatenate_features(features_train,[identifiers_train, dlls_train, symbols_train])
X_test = concatenate_features(features_test,[identifiers_test, dlls_test, symbols_test])

# normalize features
normalization = MinMaxScaler()
normalization.fit(X_train)
X_train = normalization.transform(X_train)
X_test = normalization.transform(X_test)


# use in a classifier
clfs_n = ["mlp", "svc", "knn", "decision tree", "randomforest"]
clfs = []
# Building deep neural network
net = tflearn.input_data(shape=[None, X_train.shape[1]])
net = tflearn.fully_connected(net, X_train.shape[1]/2, activation='relu')
net = tflearn.fully_connected(net, X_train.shape[1]/3, activation='relu')
net = tflearn.fully_connected(net, 2, activation='softmax')
net = tflearn.regression(net)
# Training
clfs.append(tflearn.DNN(net, tensorboard_verbose=0))
clfs.append(SVC(kernel='linear', probability=True))
# clfs.append(LinearSVC())
clfs.append(KNeighborsClassifier(5))
clfs.append(DecisionTreeClassifier())
clfs.append(RandomForestClassifier())
hot_labels_train = hot_encondig(labels_train)


# fprs = []
# fnrs = []
# accs = []
# f1s = []
# thresholds = []
if THRESHOLD:
    for n in range(len(clfs_n)):
        if clfs_n[n] == 'mlp':
            clfs[n].fit(X_train, hot_labels_train)
        else:
            clfs[n].fit(X_train, labels_train)
        csv_out = open(clfs_n[n] + "_results.csv", "a")
        c = csv.writer(csv_out)
        c.writerow(["threshold", "accuracy", "f1score", "fpr", "fnr", "tpr", "tnr"])
        for t in np.arange(0,1,0.0005):
            if clfs_n[n] == 'mlp':
                pred = clfs[n].predict(X_test)
            else:
                pred = clfs[n].predict_proba(X_test)
            pred = prob_to_class_threshold(pred, t)
            print "Threshold:",t
            # print "FAR:", far(labels_test, pred)
            # print "FRR:", frr(labels_test, pred)
            # acc = accuracy(labels_test, pred)
            # print "Accuracy:", acc
            print "Accuracy:", accuracy_score(labels_test, pred)
            print "F1Score:", f1_score(labels_test, pred)
            acc = accuracy_score(labels_test, pred)
            cm = confusion_matrix(labels_test, pred)
            # Thus in binary classification, the count of true negatives is C_{0,0}, false negatives is C_{1,0}, true positives is C_{1,1} and false positives is C_{0,1}.
            print cm
            tn = cm[0][0]
            fn = cm[1][0]
            tp = cm[1][1]
            fp = cm[0][1]
            f1 = f1_score(labels_test, pred)
            tpr = tp/float(tp+fn)
            fnr = 1 - tpr
            fpr = fp/float(fn+tn)
            tnr = tn/float(fp+tn)
            print "FPR:",fpr
            print "FNR:",fnr
            c.writerow([t, acc, f1, fpr, fnr, tpr, tnr])
            # thresholds.append(t)
            # accs.append(acc)
            # f1s.append(f1)
            # fprs.append(fpr)
            # fnrs.append(fnr)
        # x = thresholds
        # y_fprs = fprs
        # y_fnrs = fnrs
        # plt.figure(1)
        # plt.ylabel(u'FPR & FNR')
        # plt.xlabel(u'Threshold')
        # plt.title(classifier.upper() + ": FPR & FNR x Threshold")
        # plt.axvline(0, color="#000000", linewidth=2)
        # plt.axhline(0, color="#000000", linewidth=2)
        # x_ticks = np.arange(0,1.05,0.1)
        # plt.xticks(x_ticks)
        # plt.yticks(x_ticks)
        # plt.ylim(-0.05,1.05)
        # plt.xlim(-0.05,1.05)
        # plt.plot(x, y_fprs, 'b-', label="FPR", linewidth=4)
        # plt.plot(x, y_fnrs, 'r-', label="FNR", linewidth=4)
        # plt.legend(loc=1)
        # plt.grid(True)
        # plt.show()

else:
    pred = clf.predict(X_test)
    # if classifier == 'mlp':
        # pred = prob_to_class(pred)
    print "Accuracy:", accuracy_score(labels_test, pred)
    print "F1Score:", f1_score(labels_test, pred)
    print confusion_matrix(labels_test, pred)
