# -*- coding: UTF-8 -*-.
import argparse
from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score
from sklearn.metrics import confusion_matrix
from sklearn.svm import SVC
from sklearn.svm import LinearSVC
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.preprocessing import MinMaxScaler
from sklearn.grid_search import GridSearchCV
import tflearn
import matplotlib.pyplot as plt
import numpy as np
import sys
sys.path.append("./lib")
from common import cross_validation, read_csv_month_year, read_month_year, read_month_year_cumulative, hot_enconding, concatenate_features, prob_to_class, prob_to_class_threshold, read_csv_month_year_cumulative

N_FEATURES = 100
N_EXECUTIONS = 1
GW_TEST_SIZE = 0.5
MW_TEST_SIZE = 0.5
THRESHOLD = False

def params():
    parser = argparse.ArgumentParser()
    parser.add_argument('classifier', help='Classifier')
    parser.add_argument('goodwares_csv', help='Goodwares CSV location')
    parser.add_argument('malwares_csv', help='Malwares CSV Location')
    # parser.add_argument('train_month', help='Train month and year, in the format month.year')
    # parser.add_argument('test_month', help='Test month and year, in the format month.year')
    params = parser.parse_args()
    return params.classifier, params.goodwares_csv, params.malwares_csv

def format_month(text):
    m=text.split(".")
    month=m[0]
    year=m[1]
    return int(month), int(year)

if __name__ == '__main__':
    classifier, gw_csv, mw_csv = params()
    months = [1,2,3,4,5,6,7,8,9,10,11,12]
    years = [2012,2013,2014,2015,2016,2017]
    train_m = []
    for y in years:
        for m in months:
            if (m<8 and y==2016) and (m>=1 and y==2016):
                pass
            else:
                train_m.append(str(m)+"."+str(y))
    # train_m.append("1.2017")
    # train_m.append("2.2017")
    # train_m.append("3.2017")
    test_m = []
    # initialize cms matrix
    cms = np.matrix([[0, 0], [0, 0]])
    for i in range(1,len(train_m)):
        test_m.append(train_m[i])
    train_m.pop()
    for train_m, test_m in zip(train_m,test_m):
        # print "----------------------"
        # print "Train year: <=", train_m
        # print "Test year: =", test_m
        # format input month and year
        train_month, train_year = format_month(train_m)
        test_month, test_year = format_month(test_m)
        accs = []
        f1s = []
        precs = []
        recs = []

        if train_m == test_m:
            N_EXECUTIONS=10
        else:
            N_EXECUTIONS=1

        for exe in range(N_EXECUTIONS):
            # read train and test goodware samples
            gw_features_train, gw_identifiers_train, gw_dlls_train, gw_symbols_train = read_csv_month_year_cumulative(gw_csv,train_month,train_year)
            gw_features_test, gw_identifiers_test, gw_dlls_test, gw_symbols_test = read_csv_month_year(gw_csv,test_month,test_year)
            gw_labels_train = np.zeros(len(gw_features_train))
            gw_labels_test = np.zeros(len(gw_features_test))
            # read train and test malware samples
            mw_features_train, mw_identifiers_train, mw_dlls_train, mw_symbols_train = read_month_year_cumulative(mw_csv,train_month,train_year)
            mw_features_test, mw_identifiers_test, mw_dlls_test, mw_symbols_test = read_month_year(mw_csv,test_month,test_year)
            mw_labels_train = np.ones(len(mw_features_train))
            mw_labels_test = np.ones(len(mw_features_test))

            if len(gw_features_train)!=0 and len(mw_features_train)!=0 and len(gw_features_test) and len(mw_features_test):

                # create train and test sets - concatenate goodwares and malwares
                features_train = np.concatenate((gw_features_train, mw_features_train),axis=0)
                features_test = np.concatenate((gw_features_test, mw_features_test),axis=0)
                identifiers_train = np.concatenate((gw_identifiers_train, mw_identifiers_train),axis=0)
                identifiers_test = np.concatenate((gw_identifiers_test, mw_identifiers_test),axis=0)
                dlls_train = np.concatenate((gw_dlls_train, mw_dlls_train),axis=0)
                dlls_test = np.concatenate((gw_dlls_test, mw_dlls_test),axis=0)
                symbols_train = np.concatenate((gw_symbols_train, mw_symbols_train),axis=0)
                symbols_test = np.concatenate((gw_symbols_test, mw_symbols_test),axis=0)
                labels_train = np.concatenate((gw_labels_train, mw_labels_train),axis=0)
                labels_test = np.concatenate((gw_labels_test, mw_labels_test),axis=0)

                # train tfidf for each textual feature
                identifiers_tfidf = TfidfVectorizer(min_df=0.1, max_df=0.45)
                identifiers_tfidf.fit(identifiers_train)
                identifiers_train = identifiers_tfidf.transform(identifiers_train)
                identifiers_test = identifiers_tfidf.transform(identifiers_test)
                dlls_tfidf = TfidfVectorizer(min_df=0.1, max_df=0.45)
                dlls_tfidf.fit(dlls_train)
                dlls_train = dlls_tfidf.transform(dlls_train)
                dlls_test = dlls_tfidf.transform(dlls_test)
                symbols_tfidf = TfidfVectorizer(min_df=0.1, max_df=0.45)
                symbols_tfidf.fit(symbols_train)
                symbols_train = symbols_tfidf.transform(symbols_train)
                symbols_test = symbols_tfidf.transform(symbols_test)

                # concatenate numerical and textual features
                X_train = concatenate_features(features_train,[identifiers_train, dlls_train, symbols_train])
                X_test = concatenate_features(features_test,[identifiers_test, dlls_test, symbols_test])

                # normalize features
                if classifier == "svcrbf":
                    normalization = MinMaxScaler(feature_range=(-1, 1))
                else:
                    normalization = MinMaxScaler()
                normalization.fit(X_train)
                X_train = normalization.transform(X_train)
                X_test = normalization.transform(X_test)


                # use in a classifier
                if classifier == "svc":
                    clf = SVC(kernel="linear", probability=THRESHOLD)
                elif classifier == "svcrbf":
                    clf = SVC(C=1000.0, cache_size=200, class_weight=None, coef0=0.0,
                      decision_function_shape=None, degree=3, gamma=1.0, kernel='rbf',
                      max_iter=-1, probability=THRESHOLD, random_state=None, shrinking=True,
                      tol=0.001, verbose=False)
                elif classifier == "linearsvc":
                    clf = LinearSVC()
                elif classifier == "knn":
                    clf = KNeighborsClassifier(5)
                elif classifier == 'decisiontree':
                    clf = DecisionTreeClassifier()
                elif classifier == 'randomforest':
                    clf = RandomForestClassifier()
                elif classifier == 'mlp':
                    labels_train = hot_enconding(labels_train)
                    # Building deep neural network
                    net = tflearn.input_data(shape=[None, X_train.shape[1]])
                    net = tflearn.fully_connected(net, X_train.shape[1]/2, activation='relu')
                    net = tflearn.fully_connected(net, X_train.shape[1]/3, activation='relu')
                    net = tflearn.fully_connected(net, 2, activation='softmax')
                    net = tflearn.regression(net)
                    # Training
                    clf = tflearn.DNN(net, tensorboard_verbose=0)

                clf.fit(X_train, labels_train)

                fprs = []
                fnrs = []
                thresholds = []

                pred = clf.predict(X_test)
                if classifier == 'mlp':
                    pred = prob_to_class(pred)
                accs.append(accuracy_score(labels_test, pred))
                f1s.append(f1_score(labels_test, pred))
                recs.append(recall_score(labels_test, pred))
                precs.append(precision_score(labels_test, pred))
                cms = cms + confusion_matrix(labels_test, pred)
                # print "Accuracy:", accuracy_score(labels_test, pred)
                # print "F1Score:", f1_score(labels_test, pred)
                # print "Recall:", recall_score(labels_test, pred)
                # print "Precision:", precision_score(labels_test, pred)
                # print confusion_matrix(labels_test, pred)
            # else:
                # print "THERE ARE NO SUFICIENT DATA"
        # print number of train and test examples
        # len(gw_features_train)!=0 and len(mw_features_train)!=0 and len(gw_features_test) and len(mw_features_test):
        # print "Train:",len(gw_features_train) + len(mw_features_train)
        # print "Test:",len(gw_features_test) + len(mw_features_test)
        if len(gw_features_train)!=0 and len(mw_features_train)!=0 and len(gw_features_test) and len(mw_features_test):
            accs = np.array(accs)
            f1s = np.array(f1s)
            recs = np.array(recs)
            precs = np.array(precs)
            acc = accs.sum()/float(N_EXECUTIONS)
            f1 = f1s.sum()/float(N_EXECUTIONS)
            rec = recs.sum()/float(N_EXECUTIONS)
            prec = precs.sum()/float(N_EXECUTIONS)
            print train_m, '\t', str(acc), '\t', str(f1), '\t', str(rec), '\t', str(prec)
        # print "Acurácia Média:", accs.sum()/float(N_EXECUTIONS)
        # print "F1Score Médio:", f1s.sum()/float(N_EXECUTIONS)
        # print "Recall Médio:", recs.sum()/float(N_EXECUTIONS)
        # print "Precision Médio:", precs.sum()/float(N_EXECUTIONS)
    print cms
    # tn = 6121
    # fp = 245
    # fn = 1744
    # tp = 21230
    tn, fp, fn, tp = np.ravel(cms)
    ac = float(tp+tn)/float(tp+tn+fp+fn)
    f1 = float(2*tp)/float(2*tp+fp+fn)
    re = float(tp)/float(tp+fn)
    pr = float(tp)/float(tp+fp)
    print "Accuracy: ", str(ac)
    print "F1score: ", str(f1)
    print "Recall: ", str(re)
    print "Precision: ", str(pr)
