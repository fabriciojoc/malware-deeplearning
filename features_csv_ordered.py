# -*- coding: UTF-8 -*-.
import argparse
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.preprocessing import MinMaxScaler
import numpy as np
import sys
import csv
import os
import time
from datetime import datetime
from operator import itemgetter
sys.path.append("./lib")
from common import read_file, cross_validation, hot_enconding, concatenate_features, concatenate_features_w2v, prob_to_class, prob_to_class_threshold, headers, random_samples, read_csv_month_year, read_month_year, read_ymd_csvs

USED_FEATURES = [ "BaseOfCode", "BaseOfData", "Characteristics", "DllCharacteristics", "FileAlignment", "ImageBase", "NumberOfRvaAndSizes", "NumberOfSections", "NumberOfSymbols", "PointerToSymbolTable", "Size", "SizeOfCode", "SizeOfHeaders", "SizeOfImage", "SizeOfInitializedData",  "SizeOfUninitializedData", "Entropy", "Identify", "ImportedDlls", "ImportedSymbols"]

def params():
    parser = argparse.ArgumentParser()
    parser.add_argument('goodwares_csv', help='Goodwares CSV location')
    parser.add_argument('malwares_csv', help='Malwares CSV Location')
    params = parser.parse_args()
    return params.goodwares_csv, params.malwares_csv

# get params
gw_csv, mw_csv = params()

items = []

# get keys
k = []
for attr in USED_FEATURES:
    k.append(attr)
k.append("Time")
k.append("Label")

# open goodware and append to items
with open(gw_csv, 'rb') as file:
    reader = csv.DictReader(file)
    for row in reader:
        # convert timestamp
        t = datetime.fromtimestamp(int(row["TimeDateStamp"]))
        tts = time.mktime(t.timetuple())
        # get values
        r = []
        for attr in USED_FEATURES:
            r.append(row[attr])
        # append timstamp and label (gw = 0)
        r.append(tts)
        r.append(0)
        items.append(r)

# open malwares by day and append to items
for root, dirs, files in os.walk(mw_csv):
    for f in sorted(files):
        if f.endswith(".csv"):
            # get date and convert to timestamp
            date = f.replace(".csv","")
            t = datetime.strptime(date, "%Y-%m-%d")
            tts = time.mktime(t.timetuple())
            sample_year = int(f.split("-")[0])
            file_loc = os.path.join(root, f)
            with open(file_loc, 'rb') as file:
                reader = csv.DictReader(file)
                for row in reader:
                    # get values
                    r = []
                    for attr in USED_FEATURES:
                        r.append(row[attr])
                    # append timstamp and label (mw = 1)
                    r.append(tts)
                    r.append(1)
                    items.append(r)

# order by time
items_ordered = sorted(items, key=itemgetter(len(items[0])-2))

# write csv
csv_ordered = open('mw_attributes_full_sorted.csv', "a")
c_ordered = csv.writer(csv_ordered)
c_ordered.writerow(k)
for i in items_ordered:
    c_ordered.writerow(i)

# feature extraction

# print "Goodwares:",len(gw_features)
# print "Malwares:", len(mw_features)
#
# features = np.concatenate((gw_features, mw_features),axis=0)
# identifiers = np.concatenate((gw_identifiers, mw_identifiers),axis=0)
# dlls = np.concatenate((gw_dlls, mw_dlls),axis=0)
# symbols = np.concatenate((gw_symbols, mw_symbols),axis=0)
# labels = np.concatenate((gw_labels, mw_labels),axis=0)
#
# # TFIDF
#
# # train tfidf for each textual feature
# #identifiers_tfidf = TfidfVectorizer(min_df=0.15,max_df=0.45)
# #identifiers_tfidf.fit(identifiers)
# #identifiers_tf = identifiers_tfidf.transform(identifiers)
#
# dlls_tfidf = TfidfVectorizer(min_df=0.15, max_df=0.45)
# dlls_tfidf.fit(dlls)
# dlls_tf = dlls_tfidf.transform(dlls)
#
# symbols_tfidf = TfidfVectorizer(min_df=0.15,max_df=0.45)
# symbols_tfidf.fit(symbols)
# symbols_tf = symbols_tfidf.transform(symbols)
#
# #for i in range(1,identifiers_tf.shape[1]+1):
# #    h_tf.append("identifiers"+str(i))
# for i in range(1,dlls_tf.shape[1]+1):
#     h_tf.append("dlls"+str(i))
# for i in range(1,symbols_tf.shape[1]+1):
#     h_tf.append("symbols"+str(i))
# h_tf.append("label")
#
# # concatenate numerical and textual features
# X_tf = concatenate_features(features,[dlls_tf, symbols_tf])
#
#
# # normalization
# normalization_tfidf = MinMaxScaler()
# normalization_tfidf.fit(X_tf)
# X_tf = normalization_tfidf.transform(X_tf)
#
# csv_tf = open('features_tfidf_full.csv', "a")
# c_tf = csv.writer(csv_tf)
# c_tf.writerow(h_tf)
#
# for i in range(X_tf.shape[0]):
#     c_tf.writerow(np.concatenate((X_tf[i], [labels[i]]),axis=0))
