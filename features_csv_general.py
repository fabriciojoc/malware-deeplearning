# -*- coding: UTF-8 -*-.
import argparse
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.preprocessing import MinMaxScaler
import numpy as np
import sys
import csv
import gensim
sys.path.append("./lib")
from common import read_file, cross_validation, hot_enconding, concatenate_features, prob_to_class, prob_to_class_threshold, headers

N_FEATURES = 100
TFIDF = True

class MeanEmbeddingVectorizer(object):
    def __init__(self, word2vec):
        self.word2vec = word2vec
        # if a text is empty we should return a vector of zeros
        # with the same dimensionality as all the other vectors
        self.dim = len(word2vec.itervalues().next())

    def fit(self, X):
        return self

    def transform(self, X):
        return np.array([
            np.mean([self.word2vec[w] for w in words if w in self.word2vec]
                    or [np.zeros(self.dim)], axis=0)
            for words in X
        ])

class TfidfEmbeddingVectorizer(object):
    def __init__(self, word2vec):
        self.word2vec = word2vec
        self.word2weight = None
        self.dim = len(word2vec.itervalues().next())

    def fit(self, X):
        tfidf = TfidfVectorizer(analyzer=lambda x: x)
        tfidf.fit(X)
        # if a word was never seen - it must be at least as infrequent
        # as any of the known words - so the default idf is the max of
        # known idf's
        max_idf = max(tfidf.idf_)
        self.word2weight = defaultdict(
            lambda: max_idf,
            [(w, tfidf.idf_[i]) for w, i in tfidf.vocabulary_.items()])

        return self

    def transform(self, X):
        return np.array([
                np.mean([self.word2vec[w] * self.word2weight[w]
                         for w in words if w in self.word2vec] or
                        [np.zeros(self.dim)], axis=0)
                for words in X
            ])

def params():
    parser = argparse.ArgumentParser()
    parser.add_argument('goodwares_csv', help='Goodwares CSV location')
    parser.add_argument('malwares_csv', help='Malwares CSV Location')
    params = parser.parse_args()
    return params.goodwares_csv, params.malwares_csv

# get params
gw_csv, mw_csv = params()

# create csv file header
h = headers(gw_csv)
for i in range(1,N_FEATURES+1):
    h.append("identifiers"+str(i))
for i in range(1,N_FEATURES+1):
    h.append("dlls"+str(i))
for i in range(1,N_FEATURES+1):
    h.append("symbols"+str(i))

# read goodwares and malwares
gw_features, gw_identifiers, gw_dlls, gw_symbols = read_file(gw_csv)
mw_features, mw_identifiers, mw_dlls, mw_symbols = read_file(mw_csv)

print "Goodwares:",len(gw_features)
print "Malwares:", len(mw_features)

# create label arrays
gw_labels = np.zeros(len(gw_features))
mw_labels = np.ones(len(mw_features))

features = np.concatenate((gw_features, mw_features),axis=0)
identifiers = np.concatenate((gw_identifiers, mw_identifiers),axis=0)
dlls = np.concatenate((gw_dlls, mw_dlls),axis=0)
symbols = np.concatenate((gw_symbols, mw_symbols),axis=0)
labels = np.concatenate((gw_labels, mw_labels),axis=0)

if TFIDF:
    # train tfidf for each textual feature
    identifiers_tfidf = TfidfVectorizer(max_features=N_FEATURES)
    identifiers_tfidf.fit(identifiers)
    identifiers = identifiers_tfidf.transform(identifiers)

    dlls_tfidf = TfidfVectorizer(max_features=N_FEATURES)
    dlls_tfidf.fit(dlls)
    dlls = dlls_tfidf.transform(dlls)

    symbols_tfidf = TfidfVectorizer(max_features=N_FEATURES)
    symbols_tfidf.fit(symbols)
    symbols = symbols_tfidf.transform(symbols)

    # concatenate numerical and textual features
    X = concatenate_features(features,[identifiers, dlls, symbols])
else:
    identifiers_model = gensim.models.Word2Vec.load('w2v/identifiers.100.5.model')
    identifiers_w2v = dict(zip(identifiers_model.index2word, identifiers_model.syn0))
    identifiers_vectorizer = MeanEmbeddingVectorizer(identifiers_w2v)
    identifiers_vectorizer.fit(identifiers)
    identifiers = identifiers_vectorizer.transform(identifiers)

    dlls_model = gensim.models.Word2Vec.load('w2v/dlls.100.5.model')
    dlls_w2v = dict(zip(dlls_model.index2word, dlls_model.syn0))
    dlls_vectorizer = MeanEmbeddingVectorizer(dlls_w2v)
    dlls_vectorizer.fit(dlls)
    dlls = dlls_vectorizer.transform(dlls)

    symbols_model = gensim.models.Word2Vec.load('w2v/symbols.100.5.model')
    symbols_w2v = dict(zip(symbols_model.index2word, symbols_model.syn0))
    symbols_vectorizer = MeanEmbeddingVectorizer(symbols_w2v)
    symbols_vectorizer.fit(symbols)
    symbols = symbols_vectorizer.transform(symbols)

    # concatenate numerical and textual features
    X = concatenate_features_w2v(features,[identifiers, dlls, symbols])

csv_f = open('features_tfidf.csv', "a")
c = csv.writer(csv_f)
c.writerow(h)
for i in X:
    c.writerow(i)
